# VLA 视觉数据：走出“无损”误区，关注规模化

> **写在前面**：在具身智能（Embodied AI）特别是 VLA (Vision-Language-Action) 的实践中，数据基础设施往往比模型结构更具挑战性。我们面临的矛盾是：数据少了模型泛化能力差，数据多了存储和 I/O 又扛不住。
>
> 压缩是必须面对的课题，但这不仅是为了节省硬盘成本，更是为了让数据规模和迭代速度能上一个量级。本文提到的 foxglove 与 mcap 虽然源自我们的技术栈，但其背后的逻辑对 ROS2/rosbag 用户同样适用。
>
> （注：深度图和点云的压缩策略较为特殊，本文暂不讨论，此次聚焦于 RGB 数据。）

## 核心结论 (TL;DR)

为了平衡存储成本与训练效率，我们推荐以下配置：

-   **RGB 录制**：推荐使用 `JPEG` 格式，`quality=95`。配合 `foxglove.CompressedImage` 和 MCAP 的 `zstd` chunk 压缩。
-   **Depth 录制**：建议保持 `foxglove.RawImage` 存储 `Z16` 格式，依赖 MCAP 的 `zstd` 进行无损压缩。
-   **核心判断**：在 VLA / 机器人端到端策略训练中，JPEG(Q95) 带来的微小信息损失通常是可以忽略的；真正制约模型性能的，往往是数据的**规模**和**多样性**。
-   **避坑指南**：除非仅用于回放展示，否则**不建议**直接将训练数据存为 H.264/H.265 视频流，随机读取时的解码开销会显著拖慢训练速度（详见第 6 节）。

## 1. 问题所在：规模化带来的阵痛

当数据采集从实验室走向规模化时，我们会面临几个明显的痛点：

-   **规模化难题**：长时录制下，Raw RGB 数据会迅速消耗存储空间。
-   **训练效率瓶颈**：训练通常需要对数据进行随机采样（Shuffle），而非顺序播放。如果数据格式不当，GPU 往往会因为等待磁盘 I/O 和 CPU 解码而处于空闲状态。
-   **工程落地的权衡**：录制端追求极致的稳定，而训练端追求极致的读取速度。我们需要在两者之间寻找平衡（例如引入 Zarr 作为中间格式，见第 5 节）。

## 2. 业务背景与技术挑战

### 2.1 存储与传输的压力

随着数据量级从 GB 向 TB 甚至 PB 跨越，基础设施的压力成倍增加。

-   **成本估算**：以双臂机器人为例，两路 640x480 @ 30Hz 的 Raw RGB 数据，**每小时产生约 100 GB**。
-   **连锁反应**：对于数千小时的数据集，不仅存储成本高昂，数据的上传、云端流转和分发周期也会被极度拉长，严重影响迭代效率。
-   **稳定性风险**：极高的写入带宽需求可能会抢占工控机（NUC/Orin）的 I/O 资源，甚至影响实时控制循环的稳定性。

### 2.2 关于“保真度焦虑” (Fidelity Anxiety)

团队内部常有一种担忧：
> *“JPEG 是有损压缩，丢失的信息可能包含关键特征，导致模型性能天花板下降。”*

这种担忧在医学影像等领域是合理的，但在 VLA 领域，情况有所不同。现代端到端模型（End-to-End Visuomotor Policies）的鲁棒性主要源自**数据的多样性（Diversity）**，而非单一帧的**像素级完美度（Pixel Perfection）**。

## 3. 为什么压缩在 VLA 场景下是可接受的

核心原因在于，训练管线本身就在进行比 JPEG 更强的信息重构：

### 3.1 分辨率适配带来的信息重构
-   **原始采集**：通常为 640×480 或更高。
-   **模型输入**：常见模型输入为 224×224 或 336×336。
-   **结论**：下采样（Resize）过程丢失的高频信息，往往多于 JPEG(Q95) 的损失。因此，“像素级完美”在进入模型前其实就已经不存在了。

### 3.2 数据增强的主动干扰
为了提高模型的泛化能力，我们在训练时通常会引入 ColorJitter（颜色抖动）、Blur（模糊）、RandomResizedCrop（随机裁剪）等增强手段。模型被迫学习物体的语义和结构，而非像素值。相比之下，高质量 JPEG 带来的轻微伪影通常会被这些增强过程“淹没”。

### 3.3 定量分析
-   单帧质量分析：详见 [`JPEG保真度分析.md`](https://github.com/Zwhy2025/VLA-Vision-Data-Analysis/blob/master/JPEG保真度分析.md)
-   系统性能分析：详见 [`图像压缩性能分析.md`](https://github.com/Zwhy2025/VLA-Vision-Data-Analysis/blob/master/图像压缩性能分析.md)

## 4. 压缩策略推荐：JPEG(Q95) + Zstd

综合考虑各项指标，我们推荐 **JPEG (Q95) + Zstd** 的组合。

-   **存储/IO**：显著降低数据体积，缓解存储和传输压力。
-   **CPU 开销**：Q95 编码开销可控；相比之下，PNG 等无损格式在压缩率不高的情况下，还可能占满 CPU 单核，影响录制频率。
-   **训练友好**：支持按帧独立解码，适合随机访问。

### 4.1 方案对比

| 方案 | 特性 | 评价 |
| :--- | :--- | :--- |
| **Raw + Zstd** | 无损，文件级压缩 | **体积过大**。除非用于深度图或极高要求的 Golden Set，否则不推荐作为默认选项。 |
| **JPEG (Q95) + Zstd** | 有损，帧内压缩 | **最佳平衡点**。体积小（约 Raw 的 1/10），画质高，读取快。是通用 RGB 录制的首选。 |
| **H.264/H.265 视频** | 有损，帧间压缩 | **训练不友好**。虽然压缩率极高，但随机访问需要解码整个 GOP，会导致 Dataloader 效率极低。 |

### 4.2 训练与推理的一致性问题
关于*“训练用 JPEG，推理用 Raw 是否存在分布偏移”*的问题：

结论是存在的，但在实践中通常**可忽略**：
1.  模型更依赖结构与语义，JPEG 不会改变这些核心特征。
2.  训练数据增强覆盖了更宽的图像分布。
3.  **防御性策略**：如果确实担心，可以在训练增强中显式加入 JPEG 压缩模拟：

```python
# 可选：在训练数据增强中加入 JPEG 压缩模拟
import albumentations as A

transform = A.Compose([
    A.ImageCompression(quality_lower=85, quality_upper=100, p=0.5),
    # ... 其他增强
])
```

## 5. 训练友好的数据形态：Zarr

在录制端，为了数据的安全落盘和兼容性，我们通常使用 mcap 或 rosbag。但在训练端，为了追求极致的 I/O 效率，**Zarr** 是一个非常值得尝试的选择。

### 5.1 为什么推荐 Zarr
-   **随机访问友好**：基于 Chunk（分块）读取，只解码需要的局部数据，非常适合随机采样训练。
-   **并发友好**：支持多进程并发读取，多个 worker 可以读取不同的 chunk，减少锁竞争。
-   **压缩可控**：支持对 chunk 级别进行压缩配置（如 zstd, blosc 等），便于在吞吐量和压缩比之间调优。

### 5.2 推荐工作流 (录制与训练解耦)
我们建议将录制格式与训练格式解耦：

1.  **录制/归档**：使用 `mcap` (或 rosbag) 作为“事实来源”（Source of Truth），确保数据完整性和时间对齐。
2.  **预处理**：离线将 mcap 数据解包、重采样、对齐，然后转换为 **Zarr** 格式。
3.  **训练**：直接加载 Zarr 数据。虽然增加了一步预处理，但这能显著提升训练时的 Epoch 迭代速度，磨刀不误砍柴工。

## 6. 视频流 vs. 序列帧：关于时序信息的误解

最后，关于是否应该将数据存为视频文件（如 mp4），我们需要厘清一个概念。

### 6.1 “需要时序” ≠ “存成视频文件”
VLA 任务通常需要历史信息（Temporal），但这并不意味着数据必须以视频容器格式存储。
存储一串连续的 JPEG 帧，训练时按需读取过去几帧，同样能提供时序信息，且更加灵活。

### 6.2 视频编码在训练中的局限性
H.264/H.265 为了追求高压缩率，使用了 P 帧和 B 帧（依赖前后帧）。这意味着如果你需要随机读取第 100 帧，解码器可能需要先解码第 1 到 99 帧才能构建出目标帧。
在训练进行随机采样（Shuffle）时，这种机制会带来巨大的 CPU 和 I/O 开销，成为训练速度的瓶颈。

### 6.3 建议
-   **训练数据**：优先保持“逐帧独立”的形态（如 JPEG 序列或 Zarr）。
-   **展示数据**：如果需要制作演示视频，建议离线转码生成 mp4，而不要让展示需求决定了训练数据的存储格式。
